# Deep-Learning-Model-for-Roundabout-Safety-Perception-Prediction
# ğŸ§  TabTransformer Model - 1000 Epochs

This repository contains the implementation of a deep learning model using the **TabTransformer architecture** to predict outcomes from tabular data â€” trained for a full **1000 epochs** for robust performance and detailed learning analysis.

## ğŸ“Œ Overview

Traditional models like XGBoost and Random Forest are strong contenders for tabular data, but what happens when transformers meet tables?  
This project explores that very idea using **TabTransformer**, a novel DL architecture that applies the attention mechanism to categorical embeddings for enhanced feature interactions.

> ğŸš€ **Use Case**: Predicting user safety perceptions at roundabouts based on socio-demographic and behavioral data collected through questionnaires.

## ğŸ›  Features

- âš™ï¸ **TabTransformer** deep learning architecture
- ğŸ“Š Clean and preprocessed tabular dataset (categorical + continuous)
- ğŸ” **1000 epochs** of training for deep representation learning
- ğŸ“ˆ Robust evaluation metrics: Precision, Recall, F1-score, MCC, AUC
- ğŸ“‰ Training & validation visualizations using loss and accuracy curves

## ğŸ§ª Model Highlights

- ğŸ“Œ **Model**: TabTransformer (categorical embeddings + transformer blocks)
- ğŸ‹ï¸ **Epochs**: 1000
- ğŸ“Š **Macro-Averaged Metrics**:
  - Precision: **78%**
  - Recall: **72%**
  - F1-Score: **72%**
  - MCC: **0.65**
  - AUC: **93%**

These metrics reflect the modelâ€™s ability to identify nuanced safety perception patterns among varied user profiles â€” supporting intelligent urban planning.

## ğŸ“ Files

- `tabtransformer model 1000 epochs.ipynb`: The main notebook containing model building, training, evaluation, and analysis.

## ğŸ§  About TabTransformer

Originally introduced by **Huang et al. (2020)**, TabTransformer integrates **self-attention** with **MLP layers** to better handle categorical features in tabular data. Unlike traditional approaches, it learns contextual relationships between feature values â€” making it ideal for complex datasets.
---

## ğŸ§© Model Architecture Summary

- ğŸ¯ Embedding layers for high-cardinality categorical inputs
- ğŸ§© Multi-head Self-Attention for deep feature encoding
- ğŸ§® Fully connected MLP head for final classification

All training is performed using **TensorFlow/Keras** with early stopping and dropout regularization techniques.
---

## ğŸ“ˆ Visual Results

The notebook includes detailed training analysis:
- ğŸ“‰ Loss vs. Epochs
- ğŸ¯ Accuracy vs. Epochs
- ğŸ” Confusion Matrix
- ğŸ“Š ROC Curve

---
## ğŸ§ª Research Internship Context

This project was developed during my **Research Internship** at the  
**[SAFETRIP Lab, IIT Roorkee](https://civil.iitr.ac.in/SAFETRIP/index.html)**, under the guidance of transportation engineering experts.  
The model contributes to **automated safety perception profiling** using survey data â€” enabling data-driven decision-making for safer urban infrastructure planning.

> ğŸ›ï¸ **Institution**: Indian Institute of Technology, Roorkee  
> ğŸ§‘â€ğŸ”¬ **Lab**: SAFETRIP (Safety Analytics and Forecasting for Equitable Transportation & Road Infrastructure Planning) Lab  
> ğŸ—“ï¸ **Duration**: *May 2025 â€“ July 2025*

---

## ğŸ™‹â€â™€ï¸ Contributions

This project was entirely implemented by **Pratibha Yadav** as part of a research internship at **IIT Roorkee**.  
For queries or collaborations, feel free to connect:

- [LinkedIn]((https://www.linkedin.com/in/khushipratibha/)/)  

---

## ğŸŒŸ Acknowledgements

Special thanks to the faculty and researchers at SAFETRIP Lab, IIT Roorkee, for their guidance and the opportunity to work on real-world transport safety analytics.
